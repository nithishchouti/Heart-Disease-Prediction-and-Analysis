# -*- coding: utf-8 -*-
"""Heart Disease Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16Srj_YT2MVSrrU1TMIALnywxJESyxV67

# Heart Disease Prediction

## Installing the desired version of Scikit Learn
"""

!pip install scikit-learn==1.3.2

import sklearn
print(sklearn.__version__)

"""## Importing required Libraries"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# %matplotlib inline

import os
print(os.listdir())

import warnings
warnings.filterwarnings('ignore')

"""## Loading the dataset"""

# Load your dataset into a DataFrame called df
dataframe = pd.read_csv('dataset_heart.csv')

dataframe.info()

"""## Pre-processing of the Dataset

### Removing Duplicates
"""

# Remove duplicate values
dataframe.drop_duplicates(inplace=True)

# Print the total remaining values
print(f"Total remaining values: {len(dataframe)}")

"""### Removing negatives from Oldpeak (as they are invalid for the oldpeak)"""

# Remove negative values from the 'oldpeak' column
dataframe = dataframe[dataframe['oldpeak'] >= 0]

# Print the total remaining values
print(f"Total remaining values: {len(dataframe)}")

"""### Using Hot Deck Imputation for filling the invalid zeroes in 'colesterol' and 'resting_bps' column"""

# Specify the column names
column_names = ['cholesterol', 'resting_bp_s']

# Perform hot deck imputation
for col in column_names:
    # Create a copy of the column
    col_copy = dataframe[col].copy()

    # Identify the non-zero values
    non_zero_values = col_copy[col_copy != 0]

    # Replace the zero values with a random non-zero value
    col_copy[col_copy == 0] = non_zero_values.sample(col_copy[col_copy == 0].count(), replace=True).values

    # Update the original column
    dataframe[col] = col_copy

# Print the updated DataFrame
print(dataframe)

# Print the total remaining values
print(f"Total remaining values: {len(dataframe)}")

"""### Using the cleaned dataset set for further evaluation"""

#Uploading the Cleaned Dataset
df = pd.read_csv('cleaned_dataset_heart.csv')

df.head()

df.tail()

df.shape

"""## Feature Extraction

### Dropping the 'fasting_blood_sugar' column as 77% of the data contains zero and has no meaning to our classification. The 'tagert' is the output value.
"""

#Feature Extraction
x_data = df.drop(['target', 'fasting_blood_sugar'], axis = 1)
y = df['target']

"""### Perform PCA on the feature data"""

# Import the necessary libraries
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier

# Perform PCA on the feature data (x_data)
pca = PCA(n_components=9)  # Choose the number of principal components you want to retain
x_pca = pca.fit_transform(x_data)

# Print the explained variance ratio of the principal components
print("Explained Variance Ratio:", pca.explained_variance_ratio_)

# Visualize the explained variance ratio
import matplotlib.pyplot as plt
plt.figure(figsize=(8, 6))
plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)
plt.xlabel("Number of Principal Components")
plt.ylabel("Explained Variance Ratio")
plt.title("Scree Plot")
plt.show()

"""## Train Test Split"""

# Split the transformed data (x_pca) into training and testing sets
x_train_pca, x_test_pca, y_train, y_test = train_test_split(x_pca, y, test_size=0.2, random_state=0, stratify=y)

"""## Machine Learning Algorithms

### Logistic Regression
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

max_accuracy = 0
for x in range(20):
    lr = LogisticRegression(random_state=x)
    lr.fit(x_train_pca, y_train)
    y_pred_lr = lr.predict(x_test_pca)
    current_accuracy = round(accuracy_score(y_test, y_pred_lr) * 100, 2)
    if current_accuracy > max_accuracy:
        max_accuracy = current_accuracy
        best_x = x

lr = LogisticRegression(random_state=best_x)
lr.fit(x_train_pca, y_train)
y_pred_lr = lr.predict(x_test_pca)

# Calculate the evaluation metrics
score_lr = round(accuracy_score(y_test, y_pred_lr) * 100, 2)
precision = round(precision_score(y_test, y_pred_lr) * 100, 2)
recall = round(recall_score(y_test, y_pred_lr) * 100, 2)
f1 = round(f1_score(y_test, y_pred_lr) * 100, 2)

# Print the results
print("Logistic Regression Performance:")
print("Accuracy: {0}%".format(score_lr))
print("Precision: {0}%".format(precision))
print("Recall: {0}%".format(recall))
print("F1-score: {0}%".format(f1))

"""### Support Vector Machine"""

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

max_accuracy = 0
for x in range(20):
    svm = SVC(random_state=x)
    svm.fit(x_train_pca, y_train)
    y_pred_svm = svm.predict(x_test_pca)
    current_accuracy = round(accuracy_score(y_test, y_pred_svm) * 100, 2)
    if current_accuracy > max_accuracy:
        max_accuracy = current_accuracy
        best_x = x

svm = SVC(random_state=best_x)
svm.fit(x_train_pca, y_train)
y_pred_svm = svm.predict(x_test_pca)

# Calculate the evaluation metrics
score_svm = round(accuracy_score(y_test, y_pred_svm) * 100, 2)
precision = round(precision_score(y_test, y_pred_svm) * 100, 2)
recall = round(recall_score(y_test, y_pred_svm) * 100, 2)
f1 = round(f1_score(y_test, y_pred_svm) * 100, 2)

# Print the results
print("Support Vector Machine Performance:")
print("Accuracy: {0}%".format(score_svm))
print("Precision: {0}%".format(precision))
print("Recall: {0}%".format(recall))
print("F1-score: {0}%".format(f1))

"""### K-Nearest Neighbours"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

max_accuracy = 0
for k in range(1, 21):
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(x_train_pca, y_train)
    y_pred_knn = knn.predict(x_test_pca)
    current_accuracy = round(accuracy_score(y_test, y_pred_knn) * 100, 2)
    if current_accuracy > max_accuracy:
        max_accuracy = current_accuracy
        best_k = k

knn = KNeighborsClassifier(n_neighbors=best_k)
knn.fit(x_train_pca, y_train)
y_pred_knn = knn.predict(x_test_pca)

# Calculate the evaluation metrics
score_knn = round(accuracy_score(y_test, y_pred_knn) * 100, 2)
precision = round(precision_score(y_test, y_pred_knn) * 100, 2)
recall = round(recall_score(y_test, y_pred_knn) * 100, 2)
f1 = round(f1_score(y_test, y_pred_knn) * 100, 2)

# Print the results
print("K-Nearest Neighbors Classifier Performance:")
print("Accuracy: {0}%".format(score_knn))
print("Precision: {0}%".format(precision))
print("Recall: {0}%".format(recall))
print("F1-score: {0}%".format(f1))

"""### Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

max_accuracy = 0
for x in range(20):
    dt = DecisionTreeClassifier(random_state=x)
    dt.fit(x_train_pca, y_train)
    y_pred_dt = dt.predict(x_test_pca)
    current_accuracy = round(accuracy_score(y_test, y_pred_dt) * 100, 2)
    if current_accuracy > max_accuracy:
        max_accuracy = current_accuracy
        best_x = x

dt = DecisionTreeClassifier(random_state=best_x)
dt.fit(x_train_pca, y_train)
y_pred_dt = dt.predict(x_test_pca)

# Calculate the evaluation metrics
score_dt = round(accuracy_score(y_test, y_pred_dt) * 100, 2)
precision = round(precision_score(y_test, y_pred_dt) * 100, 2)
recall = round(recall_score(y_test, y_pred_dt) * 100, 2)
f1 = round(f1_score(y_test, y_pred_dt) * 100, 2)

# Print the results
print("Decision Tree Classifier Performance:")
print("Accuracy: {0}%".format(score_dt))
print("Precision: {0}%".format(precision))
print("Recall: {0}%".format(recall))
print("F1-score: {0}%".format(f1))

"""### Naive Bayes"""

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

max_accuracy = 0
for x in range(20):
    nb = GaussianNB()
    nb.fit(x_train_pca, y_train)
    y_pred_nb = nb.predict(x_test_pca)
    current_accuracy = round(accuracy_score(y_test, y_pred_nb) * 100, 2)
    if current_accuracy > max_accuracy:
        max_accuracy = current_accuracy
        best_x = x

nb = GaussianNB()
nb.fit(x_train_pca, y_train)
y_pred_nb = nb.predict(x_test_pca)

# Calculate the evaluation metrics
score_nb = round(accuracy_score(y_test, y_pred_nb) * 100, 2)
precision = round(precision_score(y_test, y_pred_nb) * 100, 2)
recall = round(recall_score(y_test, y_pred_nb) * 100, 2)
f1 = round(f1_score(y_test, y_pred_nb) * 100, 2)

# Print the results
print("Naive Bayes Classifier Performance:")
print("Accuracy: {0}%".format(score_nb))
print("Precision: {0}%".format(precision))
print("Recall: {0}%".format(recall))
print("F1-score: {0}%".format(f1))

"""### XBBoost"""

from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

max_accuracy = 0
for x in range(20):
    xgb = XGBClassifier(random_state=x)
    xgb.fit(x_train_pca, y_train)
    y_pred_xgb = xgb.predict(x_test_pca)
    current_accuracy = round(accuracy_score(y_test, y_pred_xgb) * 100, 2)
    if current_accuracy > max_accuracy:
        max_accuracy = current_accuracy
        best_x = x

xgb = XGBClassifier(random_state=best_x)
xgb.fit(x_train_pca, y_train)
y_pred_xgb = xgb.predict(x_test_pca)

# Calculate the evaluation metrics
score_xgb = round(accuracy_score(y_test, y_pred_xgb) * 100, 2)
precision = round(precision_score(y_test, y_pred_xgb) * 100, 2)
recall = round(recall_score(y_test, y_pred_xgb) * 100, 2)
f1 = round(f1_score(y_test, y_pred_xgb) * 100, 2)

# Print the results
print("XGBoost Classifier Performance:")
print("Accuracy: {0}%".format(score_xgb))
print("Precision: {0}%".format(precision))
print("Recall: {0}%".format(recall))
print("F1-score: {0}%".format(f1))

"""### Neural Network"""

from keras.models import Sequential
from keras.layers import Dense
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import numpy as np

# Hyperparameter tuning for Neural Network using MLPClassifier
max_accuracy = 0
for x in range(20):
    nn = MLPClassifier(random_state=x)
    nn.fit(x_train_pca, y_train)
    y_pred_nn = nn.predict(x_test_pca)
    current_accuracy = round(accuracy_score(y_test, y_pred_nn) * 100, 2)
    if current_accuracy > max_accuracy:
        max_accuracy = current_accuracy
        best_x = x

# Create and train a Neural Network model using Keras
model = Sequential()
model.add(Dense(16, activation='relu', input_dim=x_train_pca.shape[1]))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(x_train_pca, y_train, epochs=200, batch_size=32, validation_data=(x_test_pca, y_test))

# Make predictions on the test set
y_pred_nn = model.predict(x_test_pca)
y_pred_nn = (y_pred_nn > 0.5).astype(int)

# Calculate the evaluation metrics for the Keras Neural Network model
score_nn = round(accuracy_score(y_test, y_pred_nn) * 100, 2)
precision_nn = round(precision_score(y_test, y_pred_nn) * 100, 2)
recall_nn = round(recall_score(y_test, y_pred_nn) * 100, 2)
f1_nn = round(f1_score(y_test, y_pred_nn) * 100, 2)

# Print the results for the Keras Neural Network model
print("Neural Network Model Performance:")
print("Accuracy: {0}%".format(score_nn))
print("Precision: {0}%".format(precision_nn))
print("Recall: {0}%".format(recall_nn))
print("F1-score: {0}%".format(f1_nn))

"""### Random Forest Classifier"""

max_accuracy = 0
for x in range(20):
    rf = RandomForestClassifier(random_state=x)
    rf.fit(x_train_pca, y_train)
    y_pred_rf = rf.predict(x_test_pca)
    current_accuracy = round(accuracy_score(y_test, y_pred_rf) * 100, 2)
    if current_accuracy > max_accuracy:
        max_accuracy = current_accuracy
        best_x = x

rf = RandomForestClassifier(random_state=best_x)
rf.fit(x_train_pca, y_train)
y_pred_rf = rf.predict(x_test_pca)

# Calculate the evaluation metrics
score_rf = round(accuracy_score(y_test, y_pred_rf) * 100, 2)
precision = round(precision_score(y_test, y_pred_rf) * 100, 2)
recall = round(recall_score(y_test, y_pred_rf) * 100, 2)
f1 = round(f1_score(y_test, y_pred_rf) * 100, 2)

# Print the results
print("Random Forest Classifier Performance:")
print("Accuracy: {0}%".format(score_rf))
print("Precision: {0}%".format(precision))
print("Recall: {0}%".format(recall))
print("F1-score: {0}%".format(f1))

"""## Evaluation Metrics

### AUC ROC Curve
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, roc_auc_score
import seaborn as sns

# Assuming you have the following variables already calculated
scores = [score_lr, score_rf, score_svm, score_knn, score_dt, score_nb, score_xgb, score_nn]
algorithms = ["Logistic Regression", "Random Forest", "Support Vector Machine", "K-Nearest Neighbors", "Decision Tree", "Naive Bayes", "XGBoost", "Neural Network"]
y_pred_models = [y_pred_lr, y_pred_rf, y_pred_svm, y_pred_knn, y_pred_dt, y_pred_nb, y_pred_xgb, y_pred_nn]

# Calculate the AUC-ROC for each model
auc_scores = []
for i in range(len(algorithms)):
    fpr, tpr, _ = roc_curve(y_test, y_pred_models[i])
    auc = roc_auc_score(y_test, y_pred_models[i])
    auc_scores.append(round(auc * 100, 2))

# Set the figure size
sns.set(rc={'figure.figsize':(15, 8)})

# Plot the AUC-ROC curves
plt.figure(figsize=(15, 8))
plt.title('AUC-ROC Curves')
for i in range(len(algorithms)):
    fpr, tpr, _ = roc_curve(y_test, y_pred_models[i])
    plt.plot(fpr, tpr, label=algorithms[i])
plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.legend(loc="lower right")
plt.show()

"""### Accuracy Scores Comparison"""

import pandas as pd

scores = [score_lr,score_rf,score_svm,score_knn,score_dt,score_nb,score_xgb, score_nn]
algorithms = ["Logistic Regression","Random Forest","Support Vector Machine","K-Nearest Neighbors","Decision Tree","Naive Bayes","XGBoost", "Neural Network"]

for i in range(len(algorithms)):
    print("The accuracy score achieved using "+algorithms[i]+" is: "+str(scores[i])+" %")

data = pd.DataFrame({'Accuracy': scores}, index=algorithms)

# Set the figure size
sns.set(rc={'figure.figsize':(15, 8)})

# Create the bar plot
ax = sns.barplot(data=data, x=data.index, y='Accuracy')

# Set the x and y labels
plt.xlabel("Algorithms")
plt.ylabel("Accuracy score")

"""## Saving the Model"""

# Save the model # default xgb
import pickle

model_filename = 'model.pkl'
with open(model_filename, 'wb') as file:
    pickle.dump(rf, file)
print('Model Saved Succesfully!')